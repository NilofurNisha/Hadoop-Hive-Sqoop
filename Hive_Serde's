serialization is the process of converting java object into byte of array.
Deserialization is the process of converting of byte of array into object

Why?
1. use to transfer data between nodes
2. use to store data

File formats:
1.Text file
2.XML
3.JSON
4.Avro
5.ORC
6.Parquet
7.Csv
8.Fixed data(Regex)

XML Serde:
============

xml data:
create folder in hadoop called /user/hduser/booksxml and load below data
<student>
<studid>123</studid>
<studname>Vimal</studname>
<studmarks maths=90 science=95 english=85>270</studmarks>
</student>
<student>
<studid>124</studid>
<studname>Irfan</studname>
<studmarks maths=99 science=90 english=80>269</studmarks>
</student>

Create table:
CREATE TABLE xml_student(studentid int, studentname string,mathsmark int,sciencemark int,englishmark int,totalmarks int)
ROW FORMAT SERDE 'com.ibm.spss.hive.serde2.xml.XmlSerDe'
WITH SERDEPROPERTIES (
"column.xpath.studentid"="/root/student/studid/text()",
"column.xpath.studentname"="/student/studname/text()",
"column.xpath.mathsmark"="/student/studmarks/@maths",
"column.xpath.sciencemark"="/student/studmarks/@science",
"column.xpath.englishmark"="/student/studmarks/@english",
"column.xpath.totalmarks"="/student/studmarks/text()"
)
STORED AS
INPUTFORMAT 'com.ibm.spss.hive.serde2.xml.XmlInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat'
location '/user/hduser/studentxml/'
TBLPROPERTIES (
"xmlinput.start"="<student>",
"xmlinput.end"="</student>" );

Load data into table:
load data inpath '/user/hduser/booksxml' into table xml_student;


JSON Serde
================

Download the json serde jar

$ cd ~/Downloads/
$ wget http://www.congiu.net/hive-json-serde/1.3.8/hdp23/json-serde-1.3.8-jar-with-dependencies.jar
$ cp ~/Downloads/json-serde-1.3.8-jar-with-dependencies.jar /usr/local/hive/lib/

Data:
4000001,Kristina,Chung,55,Pilot
4000002,Paige,Chen,74,Teacher
4000003,Sherri,Melton,34,Firefighter

(Json data)
{"customerid":4000001,"firstname":"Kristina","lastname":"Chung","age":55,"prof":"Pilot"}
{"customerid":4000002,"firstname":"Paige","lastname":"Chen","age":74,"prof":"Teacher"}
{"customerid":4000003,"firstname":"Sherri","lastname":"Melton","age":34,"prof":"Firefighter"}

hadoop fs -mkdir /user/hduser/customerjson/
hadoop fs -put customer.json /user/hduser/customerjson/


Create table:
CREATE TABLE tblcustomerjson(customerid int,firstname string,lastname string,age int,prof string)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
LOCATION '/user/hduser/customerjson/';

Avro Serde:
=================

AVRO is open source project that provides data serialization and data exchange services for Hadoop.
exchange data between Hadoop ecosystem and program written in any programming languages.
It uses JSON for defining data types and protocols and serializes data in a compact binary format.

create table customer_avro
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
tblproperties ('avro.schema.literal'='{
"name": "customer_record",
"type": "record",
"fields": [
{"name":"custid", "type":"int"},
{"name":"firstname", "type":"string"},
{"name":"lastname", "type":["string"},
{"name":"age", "type":["int","null"],"default":0},
{"name":"profession", "type":["string","null"],"default":null}
]}');


insert into table customer_avro select * from customerdb.tblcustomer;



CSV Serde FileFormat:
=====================
Data:
4000001,Kristina,Chung,55,"Pilot,Teacher"
4000002,Paige,Chen,74,"Teacher,Lawyer"
4000003,Sherri,Melton,34,"Firefighter,Docor"
4000004,Gretchen,Hill,66,"Computer hardware engineer,Lawyer"
4000005,Karen,Puckett,74,"Lawyer,Teacher"

Create table:
create table customer_csv(id int, fname string, lname string, age int,profession string) 
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES(
"separatorChar" = ",",
"quoteChar"     = "\"");

load data local inpath '/home/hduser/customercsv' into table customer_csv;


Fixed data length (Regex Fileformat):
========================================

CREATE EXTERNAL TABLE Employee_fixedlength (
EMP_ID          STRING,
FIRST_NAME      STRING,
LAST_NAME       STRING,
JOB_TITLE       STRING,
MGR_EMP_ID      STRING)
ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'
WITH SERDEPROPERTIES ("input.regex" = "(.{10})(.{20})(.{20})(.{20})(.{5}).*" );


Data:
EMP-ID    FIRST-NAME          LASTNAME            JOB-TITLE           MGR-EMP-ID
12301     Johnny              Begood              Programmer          12306    
12302     Ainta               Listening           Programmer          12306    
12303     Neva                Mind                Architect           12306    
12304     Joseph              Blow                Tester              12308    
12305     Sallie              Mae                 Programmer          12306    
12306     Bilbo               Baggins             Development Manager 12307    
12307     Nuther              One                 Director            11111    
12308     Yeta                Notherone           Testing Manager     12307    
12309     Evenmore            Dumbnames           Senior Architect    12307    
12310     Last                Sillyname           Senior Tester       12308


craete folder in haddop and place data inside that folder
hadoop fs -mkdir /user/hduser/regexdata

Load data inpath '/user/hduser/regexdata' into table Employee_fixedlength


Parquet file format:
====================

Column oreinted  fileformat
It stores data in binary format

create table customer_parquet(id int, fname string, lname string, age int,profession string) stored as parquet;



ORC - Optimized Row Columnr:
=========================== 

It stores data in binary format
Column oriented storage
Optimized hive fileformat interms of storage size and query performance
ORC is the only fileformat that supports update and delete opertions

create table customer_orc(id int, fname string, lname string, age int,profession string) stored as orc;



Text file:
==========
create table customer_orc(id int, fname string, lname string, age int,profession string) stored as text;




